What is your experience with microservice?

Microservices:
- Microservices are a software architectural style where an application is divided into small, independent, and loosely coupled services. Some advantages of microservices include scalability, easier maintenance, independent development, and the ability to use different technologies for different services, more fault tolerant.

What are the advantages:
- loosely coupled
- load balancing
- async communication
- easily scalable
- fault tolerant
- adds a new layer of security through API gateway


API gateway:
    - Managing the security in micro-service
    - Handles routing based on request headers
    - Handles load balancing, connects to the Discovery Server
    - Spring-cloud-starter-gateway dependency to implement API gateway
    - SSL will be terminated: If we make a call to an external service, it includes HTTPS protocol there following the TLS scheme and if we call the API gateway from outside the TLS scheme, so API gateway will terminate the SSL connection at the entrypoint of the request.
    - Spring cloud gatway: built using Spring WebFlux or Project Reactor 
    - handles request rate limiting
    - Circuit Breaker integration
    - Spring cloud discoveryclient intergration

What is Spring Cloud?
	- It is a library that is part of Spring where we can gather features like gateway, openfeign, Eureka, Loadbalancer etc.

Fall Back Mechanism:
    - Circuit Breaker Pattern:
    - Circuit breaker design pattern is used to make your microservice architecture more fault tolerant and avoid cascading failures. It is part of the Resilience4J package. So in this package we have few other modules as well:
    - Retry(how many retries we should do when there is a failure), Rate limiter (how many request should be allowed during a time duration), Circuit Breaker, Cache etc. 
	- The idea is that we have a circuit in a closed loop. This means the the services will talk with each other and request will flow.
    	- Closed: all the request will be allowed to the system. So suppose we define a window of 5 request and threshold as 50%. So if more than 50% request are failing from those 5 request -> the circuit will change from closed to open.
    	- Open: when circuit is open, no request will be allowed, that time we can define a fallback method(dummy data) to indicate that service we are calling is down. We can define a wait duration like 5 sec for circuit to be in open state and then it will change to half-open state.
    	- Half-Open: moniter the response -> means few request will pass and we can define the window of like 3 request and we can define threshold as 50%. So if more than 50% request are still failing it goes back to open state. It will continue to closed state only when 3 request are completed successfully.

Load Balancing: 
    - The primary goal of load balancing is to ensure that no single server or resource is overwhelmed with too much traffic or requests, thus optimizing performance, reliability, and availability of a system.
        - Technique used to distribute the traffic flow between the servers/replicas
    - @RibbonClient
    	- Ribbon is a client side load balancer given by Netflix that we can make use of it when the client makes a request to the server. 
    	- So Client is responsible for balancing load.
    	- load balancing approach provided by Spring Cloud Netflix Ribbon library. We can customize load balancing for specific service. 
    - we can @Autowire LoadBalancerClient class in our service and we can get the running instances of other microservices from eureka server or we can directly call @LoadBalanced on top of RestTemplate Bean definition which comes from the dependency Spring-Cloud-eureka-client.
    - So when we make a REST calls, we configure Spring cloud load balancer to balance the load.

    - Spring-Cloud-Load-Balancer: client side load balancer i used.
    - The problem is, we cannot hardcode the url, port, IP for the running server. In a real-time depending on the load, we should be able to dynamically scale the running instances of our application. So thats where Kubernetes and Docker come. When load decreases, remove the servers to do cost cutting.
    - If the load balancer exists in different server - it is called as server side load balancing - which is responsible to dispatch request to different servers

    - Traditional Approach: So basically service A makes a request to the loadbalancer which then dispatches request to other service B.
    	- DisAdvantage: 
    		- Instead of 1 remote call we are making 2 remote call.
    		- Single point of failure: where id LB fails then all the servers connected to it fail.
    		- Does not support auto-scaling.


ServiceDiscovery:
	- we are going to discover the service (where are you service), we are going to be finding you and using you, and once you are down, we are going to be removing you. And all these will happen automatically by Spring Cloud Netflix Eureka or Zookeeper (all these are service discovery clients).
	- The question is if the server is dynamically created then how do we track where this server located and how we are going to be discovering it?
	- To discover a server we need to have a IP and port number

	- whenever we start our microservices, we register them with serviceDiscovery like the IP, port of service A, B etc.
	- ServiceDiscovery will maintain the information in a map or list etc.

	Server Side Dicovery:
	- So the logic is that Service A makes a request to LB and then LB queries to ServiceDiscovery to see available running instances of Service B and sends the request to one that has less load.
	- Example: AWS ELB

	Client Side Dicovery:
	Service A directly talks with Service B. Service A gets the instance list from ServiceDiscovery and sends it back to ServiceA. Service A is client which is doing LB.
	- Netflix Eureka, Zookeper, Consul

	- To register the ip/port of different service -> create a discovery server with the dependency spring-cloud-starter-netflix-eureka-server -> add @EnableEurekaServer or generic @EnableDiscoveryClient on spring boot starter class to autoconfigure the server.
	- Make any other services you want to register with the ServiceDiscovery as client by adding the dependency: Netflix-Eureka-Client. 

	- Suppose you have Service A(3 instances) and B running. How does Service B get information about Service A? It gets it by hitting the endpoint "eureka/apps" (which is the service registry that stores all instances/apps running or connected to the ServiceDiscovery server). The data will cached. If new instances are registered then Service B will hit the endpoint "eureka/delta/app" which means Service B only wants the updated information from service registry.

Using these Rest Clients we can make REST calls:

RestTemplate:
	- we can use this client to make REST calls: restTemplate.getForObject(x,y,z)
	- a class provided by Spring that allows to consume REST APIs of different microservices.
	- used only for synchronous HTTP requests as its based on thread-per-request model.
	- every request blocks a thread until response is received. 
	- leads to scaling issues with concurrent users.

WebClient:
	- provides both sync and async consumption of HTTP request.

OpenFeign: 
	- a declarative REST client that allows us to make REST calls.
	- Step 1: Add the Dependency: spring-cloud-starter-openfeign
	- Step 2: Annotate an interface with @FeignClient where you have methods (annotated with HTTP calls and endpoint) that should gather data from different microserivce. Spring internally will take care of this. We just need to let spring know about this during our main class by making use of the @EnableFeignClient.


Spring-Boot-Actuator:
	- monitoring our applications health and metrics.
	- we can check how many threads are running on a microservice
	- how many beans we have inside that service
	- if the seriver is up or down
	- actuator/info 
	- actuator/health by default there when dependency added
- To implement it:
	- add the dependency
	- In app.properties: add the exposure.include=* to expose the endpoints



How did you implement map interface?
- for microservice impleemntaion when one was calling another -> passing dyanmic value as reference for URI variables in open fiegn. 


Hystrix Circuit Breaker:
- I used it to visualize how many of my API is failing or successful



Zipkin/Sleuth libraries:
- For distributing tracing or logging to identify where our request are made and all that.
- I implemented zipkin server and then implement the zipkin client. 
- It tells us which microservice has been called, what is the trace ID, span id.


ELK Stack:
- I used it for centralized logging purpose


How did you handle distributed transaction?
	- We used the SAGA design pattern in our microservice architecture.
	- So the scenario is customer places an order -> order gets fulfilled only if product's price is within the credit limit.
	- Order service and payment service have their own database.
	- So customer sends request to order service -> it then sends request to Payment service to validate the customer has enough balance or not. If it does, then deduct the amount from payment DB and send OK response to order service and we complete the order. But we are making uncessary amount of HTTP request calls to bunch of microservices.


	- Instead lets use SAGA Choreography pattern to implement distributed transaction. When order service gets request from the user, immediately produces/publishes an event to the Kafka Topic (name of topic is Order-Topic) and Payment service will consume that event and payment service will take request and validate the customer has enough balance to purchase that order or not.
	- Immediately, payment service will produce an event to the topic(payment-event) and order service will consume that event.

	- Orchestration: let there be a single brain who tells others what to do. So decision making is centralized. Its a request-response based thing, so we can use it at places where we need synchronous communication. So services that need to be invoked transactionally.
		- Example: sync process - sending an OTP when the user logs in successfully. 
	- Choreography: decison logic is distributed. we use event driven architecture.
		- provides loose coupling, we can add more new services, flexible and robust.
		- Problem is entire communication is asyn and decoupled. But now this observability issue can be handled by the Distributed tracing.


17. Since you are dealing with multiple microservices utils, did you use Service Registry and Service Discovery
- Microservices by nature are loosely coupled so we can use these 2 patterns using Netflix Eureka for Service Registry and Netflix Ribbon for Service Discovery.
    - So Eureka Server maintains a service registry where we can see any registered services for that network.
    - We can call any service through Ribbon. 
    - For example we have 2 micro-services, product and order:  we have 2 dependencies configured Netflix eureka and Netflix ribbon and when we run Eureka server -> microservices can register with it and store their network locations. When a microservice wants to talk with another service they go to this server or registry and eureka provides them that network location of the service.
- Service Registry is a central repository where we can register and locate our micro services and store their network location like IP address and port.
- Service Discovery is process through which microservice can talk with another microservice via network location. Microservices uses ServiceRegistry to connect to another service over a network.



Describe the architecture of your application and the components you were responsible for. 
- I used the microservice architecture where as a backend developer I relied heavily on HTTP client services like RestTemplate, ServiceDiscovery for service communication, API Gateway: to route incoming request and handling security, LoadBalancer, making services more fault tolerant using circuit breaker/retry pattern using resilience4j. Used event driven system like Kafka and SAGA Pattern(long story with many parts) for distributed transaction, deployed services within containers and orchestrated using Kubernates.




